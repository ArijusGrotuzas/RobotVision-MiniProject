{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa8653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "\n",
    "path = 'CapturedImage.png'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e173b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3a6798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "class ColorLabeler:\n",
    "    def __init__(self):\n",
    "        # initialize the colors dictionary, containing the color\n",
    "        # name as the key and the RGB tuple as the value\n",
    "        colors = OrderedDict({\n",
    "            \"orange\": (255, 95, 0),\n",
    "            \"green\": (0, 155, 130),\n",
    "            \"yellow\": (210, 170, 0),\n",
    "            \"black\": (50, 50, 50),\n",
    "            \"red\": (255, 0, 0),\n",
    "            \"blue\": (0, 90, 150)})\n",
    "        # allocate memory for the L*a*b* image, then initialize\n",
    "        # the color names list\n",
    "        self.lab = np.zeros((len(colors), 1, 3), dtype=\"uint8\")\n",
    "        self.colorNames = []\n",
    "        # loop over the colors dictionary\n",
    "        for (i, (name, rgb)) in enumerate(colors.items()):\n",
    "            # update the L*a*b* array and the color names list\n",
    "            self.lab[i] = rgb\n",
    "            self.colorNames.append(name)\n",
    "        # convert the L*a*b* array from the RGB color space\n",
    "        # to L*a*b*\n",
    "        self.lab = cv2.cvtColor(self.lab, cv2.COLOR_RGB2LAB)\n",
    "        \n",
    "    def label(self, image, c):\n",
    "        # construct a mask for the contour, then compute the\n",
    "        # average L*a*b* value for the masked region\n",
    "        mask = np.zeros(image.shape[:2], dtype=\"uint8\")\n",
    "        cv2.drawContours(mask, [c], -1, 255, -1)\n",
    "        mask = cv2.erode(mask, None, iterations=2)\n",
    "        mean = cv2.mean(image, mask=mask)[:3]\n",
    "        # initialize the minimum distance found thus far\n",
    "        minDist = (np.inf, None)\n",
    "        # loop over the known L*a*b* color values\n",
    "        for (i, row) in enumerate(self.lab):\n",
    "            # compute the distance between the current L*a*b*\n",
    "            # color value and the mean of the image\n",
    "            d = dist.euclidean(row[0], mean)\n",
    "            # if the distance is smaller than the current distance,\n",
    "            # then update the bookkeeping variable\n",
    "            if d < minDist[0]:\n",
    "                minDist = (d, i)\n",
    "        # return the name of the color with the smallest distance\n",
    "        return self.colorNames[minDist[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d6b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeDetector:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def detect(self, c):\n",
    "        # initialize the shape name and approximate the contour\n",
    "        shape = \"unidentified\"\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.04 * peri, True)\n",
    "        #print(approx)\n",
    "        #print('Moin')\n",
    "        delta_x = approx[0][0][0] - approx[1][0][0]\n",
    "        delta_y = approx[0][0][1] - approx[1][0][1]\n",
    "        theta_radians = math.atan2(delta_y, delta_x)\n",
    "        #print(theta_radians)\n",
    "        # if the shape is a triangle, it will have 3 vertices\n",
    "        if len(approx) == 3:\n",
    "            shape = \"triangle\"\n",
    "        # if the shape has 4 vertices, it is either a square or\n",
    "        # a rectangle\n",
    "        elif len(approx) == 4:\n",
    "            # compute the bounding box of the contour and use the\n",
    "            # bounding box to compute the aspect ratio\n",
    "            ((x, y), (w, h), r) = cv2.minAreaRect(approx)\n",
    "            ar = w / float(h)\n",
    "            # a square will have an aspect ratio that is approximately\n",
    "            # equal to one, otherwise, the shape is a rectangle\n",
    "            shape = \"square\" if ar >= 0.95 and ar <= 1.05 else \"rectangle\"\n",
    "        # if the shape is a pentagon, it will have 5 vertices\n",
    "        elif len(approx) == 5:\n",
    "            shape = \"pentagon\"\n",
    "        # otherwise, we assume the shape is a circle\n",
    "        else:\n",
    "            shape = \"circle\"\n",
    "        # return the name of the shape\n",
    "        try:\n",
    "            return shape, r\n",
    "        except:\n",
    "            return shape, theta_radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e3e7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "showim = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(showim)\n",
    "plt.show()\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    # apply gamma correction using the lookup table\n",
    "    LUT = cv2.LUT(image, table)\n",
    "    return LUT\n",
    "gamma = adjust_gamma(image, gamma=2.6)\n",
    "plt.figure(figsize=(20,10))\n",
    "showim = cv2.cvtColor(gamma, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(showim)\n",
    "cv2.imwrite('1_gamma_mapped.png',cv2.cvtColor(showim, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "blur = cv2.GaussianBlur(gamma,(5,5),cv2.BORDER_REFLECT)\n",
    "plt.figure(figsize=(20,10))\n",
    "showim = cv2.cvtColor(blur, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(showim)\n",
    "cv2.imwrite('2_blurred.png',cv2.cvtColor(showim, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "K = 10\n",
    "attempts=10\n",
    "twoDimage = blur.reshape((-1,3))\n",
    "twoDimage = np.float32(twoDimage)\n",
    "ret,label,center=cv2.kmeans(twoDimage,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\n",
    "center = np.uint8(center)\n",
    "res = center[label.flatten()]\n",
    "K_image = res.reshape((image.shape))\n",
    "plt.figure(figsize=(20,10))\n",
    "showim = cv2.cvtColor(K_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(showim)\n",
    "cv2.imwrite('3_kmean.png',K_image)\n",
    "plt.show()\n",
    "\n",
    "lab = cv2.cvtColor(K_image, cv2.COLOR_BGR2LAB)\n",
    "img_hsv=cv2.cvtColor(K_image, cv2.COLOR_BGR2HSV)\n",
    "img_gray=cv2.cvtColor(img_hsv, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, img_tresh = cv2.threshold(img_gray, 90, 255,cv2.THRESH_BINARY)\n",
    "ret, B_img_tresh = cv2.threshold(img_gray, 10, 255,cv2.THRESH_BINARY)\n",
    "B_img_tresh = cv2.bitwise_not(B_img_tresh)\n",
    "img_tresh = img_tresh + B_img_tresh\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "showim = cv2.cvtColor(img_tresh, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(showim)\n",
    "cv2.imwrite('4_colorspace_conv_and_thresh.png',cv2.cvtColor(showim, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "arr_cnt = cv2.findContours(img_tresh, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(arr_cnt)\n",
    "sd = ShapeDetector()\n",
    "cl = ColorLabeler()\n",
    "i=1\n",
    "# loop over the contours\n",
    "print(\"color\",\"shape\",\"cX\",\"cY\")\n",
    "for c in cnts:\n",
    "    # compute the center of the contour, then detect the name of the\n",
    "    # shape using only the contour\n",
    "    M = cv2.moments(c)\n",
    "    if M[\"m00\"] == 0:\n",
    "        continue\n",
    "    cX = int((M[\"m10\"] / M[\"m00\"]))\n",
    "    cY = int((M[\"m01\"] / M[\"m00\"]))\n",
    "    shape, rotation = sd.detect(c)\n",
    "    color = cl.label(lab, c)\n",
    "    # multiply the contour (x, y)-coordinates by the resize ratio,\n",
    "    # then draw the contours and the name of the shape on the image\n",
    "    c = c.astype(\"float\")\n",
    "    c = c.astype(\"int\")\n",
    "    print(color,shape,cX,cY)\n",
    "    box = cv2.boxPoints(cv2.minAreaRect(c))\n",
    "    box = np.intp(box) #np.intp: Integer used for indexing (same as C ssize_t; normally either int32 or int64)\n",
    "    cv2.drawContours(image, [box], 0, (125, 100, 250))\n",
    "    cv2.putText(image,str(i)+' '+color, (cX, cY), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 255), 1)\n",
    "    i+=1\n",
    "plt.figure(figsize=(20,10))\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "cv2.imwrite('5_detected.png',cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3d2cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For homography \n",
    "↓↓↓↓uv coordinates↓↓↓↓\n",
    "red rectangle 31 252\n",
    "red rectangle 52 47\n",
    "red rectangle 439 38\n",
    "red rectangle 424 261\n",
    "\n",
    "↓↓↓↓world coordinates(using robot)↓↓↓↓\n",
    "x -446.7 y -368.5\n",
    "x -296.7 y -225.1\n",
    "x -34.9 y -450.6\n",
    "x -196.8 y -603.5\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd8a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calculate the transformation matrix\n",
    "input_pts = np.float32([[31, 252],[52, 47],[439, 38],[424, 262]])\n",
    "output_pts = np.float32([[-446.7, -368.5],[-296.7, -225.1],[-34.9, -450.6],[-196.8, -603.5]])\n",
    "\n",
    "\n",
    "# Compute the perspective transform M\n",
    "H = np.float32(cv2.getPerspectiveTransform(input_pts,output_pts))\n",
    "print('Homography Matrix: \\n', H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_points = input_pts.reshape(-1,1,2).astype(np.float32)\n",
    "\n",
    "#apply homography transfrom\n",
    "cartesian_points = cv2.perspectiveTransform(transform_points, H)\n",
    "reduced_cartesian_points = np.squeeze(cartesian_points, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281cd545",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"For printing world coordinates to validate on robot\"\"\"\"\"\n",
    "image = cv2.imread(path)\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    # apply gamma correction using the lookup table\n",
    "    LUT = cv2.LUT(image, table)\n",
    "    return LUT\n",
    "gamma = adjust_gamma(image, gamma=2.6)\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "K = 10\n",
    "attempts=10\n",
    "twoDimage = blur.reshape((-1,3))\n",
    "twoDimage = np.float32(twoDimage)\n",
    "ret,label,center=cv2.kmeans(twoDimage,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\n",
    "center = np.uint8(center)\n",
    "res = center[label.flatten()]\n",
    "K_image = res.reshape((image.shape))\n",
    "\n",
    "lab = cv2.cvtColor(K_image, cv2.COLOR_BGR2LAB)\n",
    "img_hsv=cv2.cvtColor(K_image, cv2.COLOR_BGR2HSV)\n",
    "img_gray=cv2.cvtColor(img_hsv, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, img_tresh = cv2.threshold(img_gray, 90, 255,cv2.THRESH_BINARY)\n",
    "ret, B_img_tresh = cv2.threshold(img_gray, 10, 255,cv2.THRESH_BINARY)\n",
    "B_img_tresh = cv2.bitwise_not(B_img_tresh)\n",
    "img_tresh = img_tresh + B_img_tresh\n",
    "\n",
    "arr_cnt = cv2.findContours(img_tresh, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(arr_cnt)\n",
    "sd = ShapeDetector()\n",
    "cl = ColorLabeler()\n",
    "i=1\n",
    "# loop over the contours\n",
    "print(\"color\",\"number\",\"X\",\"Y\",\"rotation\")\n",
    "for c in cnts:\n",
    "    # compute the center of the contour, then detect the name of the\n",
    "    # shape using only the contour\n",
    "    M = cv2.moments(c)\n",
    "    if M[\"m00\"] == 0:\n",
    "        continue\n",
    "    cX = int((M[\"m10\"] / M[\"m00\"]))\n",
    "    cY = int((M[\"m01\"] / M[\"m00\"]))\n",
    "    shape, rotation = sd.detect(c)\n",
    "    color = cl.label(lab, c)\n",
    "    # multiply the contour (x, y)-coordinates by the resize ratio,\n",
    "    # then draw the contours and the name of the shape on the image\n",
    "    c = c.astype(\"float\")\n",
    "    c = c.astype(\"int\")\n",
    "    \n",
    "    world_coords = np.squeeze(cv2.perspectiveTransform(np.float32([cX,cY]).reshape(-1,1,2).astype(np.float32), H), axis=1)[0]\n",
    "    print(color, i,cX,cY, rotation)\n",
    "    print('world coodinates: ', world_coords[0], world_coords[1])\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5f0f7119078aa8fa5b697511bc7efd167a4bcddc3e8ed1d391f5f936fae5534"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
